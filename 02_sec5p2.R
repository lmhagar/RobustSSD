## this code file is used to reproduce the results from Section 5.2

## load necessary packages
require(foreach)
require(doParallel)
require(doSNOW)
require(lme4)
library(lmerTest)
require(ggplot2)
require(ggpubr)
require(cowplot)

expit <- function(x){1/(1 + exp(-x))}
logit <- function(x){log(x) - log(1-x)}

## set up parallelization
cores=detectCores()
cl <- makeSOCKcluster(cores[1]-1)

m <- 10000
registerDoSNOW(cl)
pb <- txtProgressBar(max = m, style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)

## this function generates physical function data from an LMM model
## before censoring; the inputs are described below
## n: sample size (both groups combined)
## prop_a: proportion of patients assigned to new treatment
## beta_0: fixed intercept term for the LMM
## sd_b0: standard of the random intercepts
## trt_eff: coefficient for the treatment effect (estimand of interest)
## mean_slope: fixed effect for time (in weeks)
## sd_slope: standard deviations of the random slopes
## sd_err: standard deviation for the error terms
## visits: (maximum) number of visits
gen_data <- function(n, prop_a = 2/3, beta_0 = 70, sd_b0 = 5,
                     trt_eff = -9.5, mean_slope = -0.25, sd_slope = 0.01,
                     sd_err = 1, visits = 6) {
  
  ## get time points for the visits
  t_vec <- seq(4, 4*visits, 4)
  
  ## get subject-level contributions
  A   <- rbinom(n, 1, prop_a)
  b0  <- rnorm(n, 0, sd_b0)
  b1  <- rnorm(n, mean_slope, sd_slope)
  
  ## get baseline measurement including random intercept and measurement error
  y0 <- beta_0 + b0 + rnorm(n, 0, sd_err)
  
  ## expand subject-level variables across visits
  ID  <- rep(1:n, each = visits)
  A_rep  <- rep(A,  each = visits)
  y0_rep <- rep(y0, each = visits)
  b0_rep <- rep(b0, each = visits)
  b1_rep <- rep(b1, each = visits)
  t_rep  <- rep(t_vec, n)
  
  ## mean structure for response
  mu <- beta_0 + b0_rep + trt_eff*A_rep + b1_rep*t_rep
  
  ## generate noisy outcomes
  y <- mu + rnorm(n*visits, 0, sd_err)
  
  ## compile the pre-dropout data set
  data.frame(ID = ID, y0 = y0_rep, A  = A_rep, t  = t_rep, y  = y)
}

## this function takes a data set generated by gen_data() as input 
## and returns a censored data set; censoring is implemented such that
## dropout depends only on the value at the previous time point
## the inputs are as follows:
## dat: a data set generated by data_gen()
## alpha: the intercept for the censoring logistic regression model
## beta: the coefficient for the previous score in the logistic regression
## visits: the (maximum) number of visits
censor_prev <- function(dat, alpha = 14.5, beta = -0.25, visits = 6) {
  
  ## order data according to time point
  dat <- dat[order(dat$t, dat$ID),]
  
  n <- length(unique(dat$ID))
  
  ## initialize vector r (equal to 1 if time point is observed)
  r_v <- rep(1, n)
  r_vec <- rep(1, n)
  y_vec <- subset(dat, dat$t == 4)$y
  
  ## iterate over the maximum number of visits
  for (v in 2:visits){
    ## get previous y-value to compute dropout probability
    y_prev <- subset(dat, dat$t == 4*(v-1))$y
    p_dropout <- expit(alpha + beta*y_prev)
    
    ## set r_v to 0 if already dropped or dropped at current time
    drop_v <- as.numeric(runif(n) < p_dropout)
    r_v <- ifelse(r_v, 1 - drop_v, 0) 
    
    ## set dropped observations to NA
    y_v <- subset(dat, dat$t == 4*v)$y
    y_v <- ifelse(r_v, y_v, NA)
    
    ## append results from this visit time
    r_vec <- c(r_vec, r_v)
    y_vec <- c(y_vec, y_v)
    
  }
  
  ## add r covariate and censored data to data frame
  dat$r <- r_vec
  dat$y <- y_vec
  
  ## sort by patient ID
  dat <- dat[order(dat$ID, dat$t), ]
  
  return(dat)
}

## this function takes a data set generated by gen_data() as input 
## and returns a censored data set; censoring is implemented such that
## dropout depends on the value at the previous time point and the time
## the inputs are as follows:
## dat: a data set generated by data_gen()
## alpha: the intercept for the censoring logistic regression model
## beta: the coefficient for the previous score in the logistic regression
## gamma: the coefficient for time in the logistic regression
## visits: the (maximum) number of visits
censor_time <- function(dat, alpha = 18.1, beta = -0.25, gamma = -0.25, visits = 6) {
  
  ## order data according to time point
  dat <- dat[order(dat$t, dat$ID),]
  
  n <- length(unique(dat$ID))
  
  ## initialize vector r (equal to 1 if time point is observed)
  r_v <- rep(1, n)
  r_vec <- rep(1, n)
  y_vec <- subset(dat, dat$t == 4)$y
  
  ## iterate over the maximum number of visits
  for (v in 2:visits){
    ## get previous y-value to compute dropout probability
    y_prev <- subset(dat, dat$t == 4*(v-1))$y
    p_dropout <- expit(alpha + beta*y_prev + gamma*4*v)
    
    ## set r_v to 0 if already dropped or dropped at current time
    drop_v <- as.numeric(runif(n) < p_dropout)
    r_v <- ifelse(r_v, 1 - drop_v, 0) 
    
    ## set dropped observations to NA
    y_v <- subset(dat, dat$t == 4*v)$y
    y_v <- ifelse(r_v, y_v, NA)
    
    ## append results from this visit time
    r_vec <- c(r_vec, r_v)
    y_vec <- c(y_vec, y_v)
    
  }
  
  ## add r covariate and censored data to data frame
  dat$r <- r_vec
  dat$y <- y_vec
  
  ## sort by patient ID
  dat <- dat[order(dat$ID, dat$t), ]
  
  return(dat)
}

## this function takes a data set generated by gen_data() as input 
## and returns a censored data set; censoring is implemented such that
## dropout depends on the value at the previous time point and the treatment assignment
## the inputs are as follows:
## dat: a data set generated by data_gen()
## alpha: the intercept for the censoring logistic regression model
## beta: the coefficient for the previous score in the logistic regression
## gamma: the coefficient for treatment assignment in the logistic regression
## visits: the (maximum) number of visits
censor_trt <- function(dat, alpha = 15.95, beta = -0.25, gamma = -2.5, visits = 6) {
  
  ## order data according to time point
  dat <- dat[order(dat$t, dat$ID),]
  
  n <- length(unique(dat$ID))
  
  ## initialize vector r (equal to 1 if time point is observed)
  r_v <- rep(1, n)
  r_vec <- rep(1, n)
  y_vec <- subset(dat, dat$t == 4)$y
  
  ## iterate over the maximum number of visits
  for (v in 2:visits){
    ## get previous y-value to compute dropout probability
    y_prev <- subset(dat, dat$t == 4*(v-1))$y
    p_dropout <- expit(alpha + beta*y_prev + gamma*dat$A)
    
    ## set r_v to 0 if already dropped or dropped at current time
    drop_v <- as.numeric(runif(n) < p_dropout)
    r_v <- ifelse(r_v, 1 - drop_v, 0) 
    
    ## set dropped observations to NA
    y_v <- subset(dat, dat$t == 4*v)$y
    y_v <- ifelse(r_v, y_v, NA)
    
    ## append results from this visit time
    r_vec <- c(r_vec, r_v)
    y_vec <- c(y_vec, y_v)
    
  }
  
  ## add r covariate and censored data to data frame
  dat$r <- r_vec
  dat$y <- y_vec
  
  ## sort by patient ID
  dat <- dat[order(dat$ID, dat$t), ]
  
  return(dat)
}

## this function takes a data set generated by gen_data() as input 
## and returns a censored data set; censoring is implemented such that
## dropout depends only on the baseline score
## the inputs are as follows:
## dat: a data set generated by data_gen()
## alpha: the intercept for the censoring logistic regression model
## beta: the coefficient for the previous score in the logistic regression
## visits: the (maximum) number of visits
censor_base <- function(dat, alpha = 16.7, beta = -0.25, visits = 6) {
  
  ## order data according to time point
  dat <- dat[order(dat$t, dat$ID),]
  
  n <- length(unique(dat$ID))
  
  ## initialize vector r (equal to 1 if time point is observed)
  r_v <- rep(1, n)
  r_vec <- rep(1, n)
  y_vec <- subset(dat, dat$t == 4)$y
  
  ## iterate over the maximum number of visits
  for (v in 2:visits){
    ## compute dropout probability based on baseline score
    p_dropout <- expit(alpha + beta*dat$y0)
    
    ## set r_v to 0 if already dropped or dropped at current time
    drop_v <- as.numeric(runif(n) < p_dropout)
    r_v <- ifelse(r_v, 1 - drop_v, 0) 
    
    ## set dropped observations to NA
    y_v <- subset(dat, dat$t == 4*v)$y
    y_v <- ifelse(r_v, y_v, NA)
    
    ## append results from this visit time
    r_vec <- c(r_vec, r_v)
    y_vec <- c(y_vec, y_v)
    
  }
  
  ## add r covariate and censored data to data frame
  dat$r <- r_vec
  dat$y <- y_vec
  
  ## sort by patient ID
  dat <- dat[order(dat$ID, dat$t), ]
  
  return(dat)
}

## consider the six scenarios
ns <- seq(80,200,10)

## Psi_1: iterate over sample sizes
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k)
                       
                       ## generate and censor data
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_prev(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       ## return results
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("lmm_prev_n_", n, ".csv"), row.names = FALSE)
}

## repeat for Psi_2 model
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 130000)
                       
                       ## generate and censor data (more variability in random slopes)
                       temp.dat <- gen_data(n, sd_slope = 0.1)
                       temp.dat <- censor_prev(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       ## return results
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("lmm_slope_n_", n, ".csv"), row.names = FALSE)
}

## Psi_3: iterate over sample sizes
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 260000)
                       
                       ## generate and censor data (dropout depends on time)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_time(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("lmm_time_n_", n, ".csv"), row.names = FALSE)
}

## Psi_4: iterate over sample sizes
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 390000)
                       
                       ## generate and censor data (dropout depends on treatment)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_trt(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("lmm_trt_n_", n, ".csv"), row.names = FALSE)
}

## Psi_5: iterate over sample sizes
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 520000)
                       
                       ## generate and censor data (dropout depends on baseline score)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_base(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("lmm_base_n_", n, ".csv"), row.names = FALSE)
}

## Psi_6: iterate over sample sizes
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 650000)
                       
                       ## generate and censor data (larger variability in random intercepts)
                       temp.dat <- gen_data(n, sd_b0 = 10)
                       temp.dat <- censor_prev(temp.dat, alpha = 15.1, beta = -0.25)
                       
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("lmm_var_n_", n, ".csv"), row.names = FALSE)
}

## get the plots for Figure 2

## this function takes the sampling distribution estimates of p-values
## and constructs linear approximations to estimate power for one-sided hypotheses;
## the inputs are described as follows:
## m1 is the first sampling distribution estimate
## m2 is the second sampling distribution estimate
## n0 is first sample size
## n1 is second sample size
## lb is lower bound for linear approximations
## ub is upper bound for linear approximations
## by is the increment for linear approximations
## gam is the threshold (i.e., alpha for type I error rate)
pwr_one_sided <- function(m1, m2, n0, n1, lb, ub, by, gam){
  
  ## get logits for the p-values in one tail of 
  ls <- logit(m1)
  li <- logit(m2)
  
  ## adjust any infinite logits
  ls <- ifelse(ls == -Inf, min(subset(ls, is.finite(ls))) - 1, ls)
  ls <- ifelse(ls == Inf, max(subset(ls, is.finite(ls))) + 1, ls)
  
  ## adjust any infinite logits
  li <- ifelse(li == -Inf, min(subset(li, is.finite(li))) - 1, li)
  li <- ifelse(li == Inf, max(subset(li, is.finite(li))) + 1, li)
  
  slopes <- NULL
  ints <- NULL
  
  ## construct the slopes using the order statistics of the sampling
  ## distribution estimates
  ls_s <- ls[order(ls)]
  li_s <- li[order(li)]
  
  slopes <- (li_s - ls_s)/(n1-n0)
  ints <- ls_s - slopes*n0
  
  ## create matrix to calculate power
  samps <- seq(lb,ub,by)
  res.vec <- NULL
  for (i in 1:length(samps)){
    ## check which probabilities are less than the threshold 
    stop.temp <- ints + slopes*samps[i] <= logit(gam)
    res.vec[i] <- mean(stop.temp)
  }
  
  ## return matrix with samples sizes and estimated power
  return(cbind(samps, res.vec))
  
}

## get power curve using naive simulation
alpha <- 0.025
pwr <- NULL
## read in results from each saved .csv file and calculate power empirically
for (j in 1:length(n_vals)){
  n <- n_vals[j]
  temp <- read.csv(paste0("lmm_prev_n_", n, ".csv"))$V2
  pwr[j] <- mean(temp <= alpha)
}
## save results
pwr1 <- pwr

## get power curve using Algorithm 2
temp1.df <- pwr_one_sided(read.csv(paste0("lmm_prev_n_100.csv"))$V2,
                          read.csv(paste0("lmm_prev_n_180.csv"))$V2,
                          100, 180, 80, 200, 1, 0.025)

## combine different power curve estimates into one data frame
df1 <- data.frame(n = c(seq(80, 200, 10), seq(80, 200, 1)),
                  power = c(pwr1, temp1.df[,2]),
                  curve = c(rep("C_Simulation", length(seq(80, 200, 10))),
                            rep("A_Algorithm 2", length(seq(80, 200, 1)))))

## load in colour palette
cbb <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

## create subplot
plot1 <- ggplot(df1, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[1]*': Dropout by Previous Score')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="none") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1, "cm")) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2)

## repeat for the second model
pwr <- NULL
for (j in 1:length(n_vals)){
  n <- n_vals[j]
  temp <- read.csv(paste0("lmm_slope_n_", n, ".csv"))$V2
  pwr[j] <- mean(temp <= alpha)
}
pwr2 <- pwr

## get power curve using Algorithm 2
temp2.df <- pwr_one_sided(read.csv(paste0("lmm_slope_n_100.csv"))$V2,
                          read.csv(paste0("lmm_slope_n_180.csv"))$V2,
                          100, 180, 80, 200, 1, 0.025)

## combine different power curve estimates into one data frame
df2 <- data.frame(n = c(seq(80, 200, 10), seq(80, 200, 1)),
                  power = c(pwr2, temp2.df[,2]),
                  curve = c(rep("C_Simulation", length(seq(80, 200, 10))),
                            rep("A_Algorithm 2", length(seq(80, 200, 1)))))

## create subplot
plot2 <- ggplot(df2, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[2]*': Larger Random-Slope Variance')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="none") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1, "cm")) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2)

## repeat for the third model
pwr <- NULL
for (j in 1:length(n_vals)){
  n <- n_vals[j]
  temp <- read.csv(paste0("lmm_time_n_", n, ".csv"))$V2
  pwr[j] <- mean(temp <= alpha)
}
pwr3 <- pwr

## get power curve using Algorithm 2
temp3.df <- pwr_one_sided(read.csv(paste0("lmm_time_n_100.csv"))$V2,
                          read.csv(paste0("lmm_time_n_180.csv"))$V2,
                          100, 180, 80, 200, 1, 0.025)

## combine different power curve estimates into one data frame
df3 <- data.frame(n = c(seq(80, 200, 10), seq(80, 200, 1)),
                  power = c(pwr3, temp3.df[,2]),
                  curve = c(rep("C_Simulation", length(seq(80, 200, 10))),
                            rep("A_Algorithm 2", length(seq(80, 200, 1)))))

## create subplot
plot3 <- ggplot(df3, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[3]*': Time-Dependent Dropout')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="none") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1, "cm")) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2)

## repeat for the fourth model
pwr <- NULL
for (j in 1:length(n_vals)){
  n <- n_vals[j]
  temp <- read.csv(paste0("lmm_trt_n_", n, ".csv"))$V2
  pwr[j] <- mean(temp <= alpha)
}
pwr4 <- pwr

## get power curve using Algorithm 2
temp4.df <- pwr_one_sided(read.csv(paste0("lmm_trt_n_100.csv"))$V2,
                          read.csv(paste0("lmm_trt_n_180.csv"))$V2,
                          100, 180, 80, 200, 1, 0.025)

## combine different power curve estimates into one data frame
df4 <- data.frame(n = c(seq(80, 200, 10), seq(80, 200, 1)),
                  power = c(pwr4, temp4.df[,2]),
                  curve = c(rep("C_Simulation", length(seq(80, 200, 10))),
                            rep("A_Algorithm 2", length(seq(80, 200, 1)))))

## create subplot
plot4 <- ggplot(df4, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[4]*': Treatment-Dependent Dropout')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="none") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1, "cm")) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2)

## repeat for the fifth model
pwr <- NULL
for (j in 1:length(n_vals)){
  n <- n_vals[j]
  temp <- read.csv(paste0("lmm_base_n_", n, ".csv"))$V2
  pwr[j] <- mean(temp <= alpha)
}
pwr5 <- pwr

## get power curve using Algorithm 2
temp5.df <- pwr_one_sided(read.csv(paste0("lmm_base_n_100.csv"))$V2,
                          read.csv(paste0("lmm_base_n_180.csv"))$V2,
                          100, 180, 80, 200, 1, 0.025)

## combine different power curve estimates into one data frame
df5 <- data.frame(n = c(seq(80, 200, 10), seq(80, 200, 1)),
                  power = c(pwr5, temp5.df[,2]),
                  curve = c(rep("C_Simulation", length(seq(80, 200, 10))),
                            rep("A_Algorithm 2", length(seq(80, 200, 1)))))

## create subplot
plot5 <- ggplot(df5, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[5]*': Dropout by Baseline Score')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="none") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1, "cm")) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2)

## repeat for the sixth model
pwr <- NULL
for (j in 1:length(n_vals)){
  n <- n_vals[j]
  temp <- read.csv(paste0("lmm_var_n_", n, ".csv"))$V2
  pwr[j] <- mean(temp <= alpha)
}
pwr6 <- pwr

## get power curve using Algorithm 2
temp6.df <- pwr_one_sided(read.csv(paste0("lmm_var_n_100.csv"))$V2,
                          read.csv(paste0("lmm_var_n_180.csv"))$V2,
                          100, 180, 80, 200, 1, 0.025)

## combine different power curve estimates into one data frame
df6 <- data.frame(n = c(seq(80, 200, 10), seq(80, 200, 1)),
                  power = c(pwr6, temp6.df[,2]),
                  curve = c(rep("C_Simulation", length(seq(80, 200, 10))),
                            rep("A_Algorithm 2", length(seq(80, 200, 1)))))

## create subplot
plot6 <- ggplot(df6, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[6]*': Larger Random-Intercept Variance')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="none") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1, "cm")) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2)

## arrange for the final plot
figp.row1 <- plot_grid(plot1 + theme(plot.margin=unit(c(0.25,0.5,0.25,0.5),"cm")), 
                       plot2 + theme(plot.margin=unit(c(0.25,0.5,0.25,0.5),"cm")),
                       rel_widths = c(1, 1))
figp.row2 <- plot_grid(plot3 + theme(plot.margin=unit(c(0.25,0.5,0.25,0.5),"cm")), 
                       plot4 + theme(plot.margin=unit(c(0.25,0.5,0.25,0.5),"cm")),
                       rel_widths = c(1, 1))
figp.row3 <- plot_grid(plot5 + theme(plot.margin=unit(c(0.25,0.5,0.25,0.5),"cm")), 
                       plot6 + theme(plot.margin=unit(c(0.25,0.5,0.25,0.5),"cm")),
                       rel_widths = c(1, 1))
figp <- plot_grid(figp.row1, figp.row2, figp.row3, nrow = 3)

## get a common legend for the larger figure
plot1.legend <- ggplot(df1, aes(x=n)) + theme_bw() +
  geom_line(aes(y = power, color=as.factor(curve), linetype = as.factor(curve)), 
            alpha = 0.9, size = 1) +
  labs(title=bquote(psi[1]*': Dropout by Previous Score')) +
  labs(x= bquote(italic(n)), y= bquote('Power')) +
  theme(plot.title = element_text(size=18,face="bold", hjust =  0.5,
                                  margin = margin(t = 0, 0, 5, 0))) +
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=18)) +
  theme(legend.position="bottom") +
  scale_color_manual(name = " ", 
                     labels = c("Algorithm 2  ", "Simulation"),
                     values = c("steelblue1", "firebrick")) +
  scale_linetype_manual(name = " ", 
                        labels = c("Algorithm 2  ", "Simulation"),
                        values = c(1, 5)) +
  ylim(0.6,1) + 
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))) +
  geom_hline(yintercept=0.9, lty = 2) +
  theme(legend.text=element_text(size=18)) +
  theme(legend.key.size = unit(1.5, "cm"))

## add legend to bottom of the plot
fig_final <- plot_grid(figp, ggpubr::get_legend(plot1.legend), ncol = 1, rel_heights = c(2.1, .1))

# output as .pdf file for the article
pdf(file = "Fig_LMM.pdf",   # The directory you want to save the file in
    width = 10.5, # The width of the plot in inches
    height = 9.75) # The height of the plot in inches

fig_final

dev.off()

## now implement the confirmatory simulations for Appendix D

## get recommended sample size (robust)
ns <- 152

## confirmation for Psi_1 (power)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 780000)
                       
                       ## generate and censor data
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_prev(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       ## return results
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_lmm_prev_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_2 (power)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 790000)
                       
                       ## generate and censor data (more variability in random slopes)
                       temp.dat <- gen_data(n, sd_slope = 0.1)
                       temp.dat <- censor_prev(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       ## return results
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_lmm_slope_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_3 (power)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 800000)
                       
                       ## generate and censor data (dropout depends on time)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_time(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_lmm_time_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_4 (power)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 810000)
                       
                       ## generate and censor data (dropout depends on treatment)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_trt(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_lmm_trt_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_5 (power)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 820000)
                       
                       ## generate and censor data (dropout depends on baseline score)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_base(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_lmm_base_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_6 (power)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 830000)
                       
                       ## generate and censor data (larger variability in random intercepts)
                       temp.dat <- gen_data(n, sd_b0 = 10)
                       temp.dat <- censor_prev(temp.dat, alpha = 15.1, beta = -0.25)
                       
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_lmm_var_n_", n, ".csv"), row.names = FALSE)
}

## repeat simulations under H0 to check type I error

## confirmation for Psi_1 (type I error)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 840000)
                       
                       ## generate and censor data
                       temp.dat <- gen_data(n, trt_eff = -10)
                       temp.dat <- censor_prev(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       ## return results
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_H0_lmm_prev_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_2 (type I error)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 850000)
                       
                       ## generate and censor data (more variability in random slopes)
                       temp.dat <- gen_data(n, sd_slope = 0.1, trt_eff = -10)
                       temp.dat <- censor_prev(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       ## return results
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_H0_lmm_slope_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_3 (type I error)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 860000)
                       
                       ## generate and censor data (dropout depends on time)
                       temp.dat <- gen_data(n, trt_eff = -10)
                       temp.dat <- censor_time(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_H0_lmm_time_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_4 (type I error)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 870000)
                       
                       ## generate and censor data (dropout depends on treatment)
                       temp.dat <- gen_data(n, trt_eff = -10)
                       temp.dat <- censor_trt(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_H0_lmm_trt_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_5 (type I error)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 880000)
                       
                       ## generate and censor data (dropout depends on baseline score)
                       temp.dat <- gen_data(n)
                       temp.dat <- censor_base(temp.dat)
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_H0_lmm_base_n_", n, ".csv"), row.names = FALSE)
}

## confirmation for Psi_6 (type I error)
for (j in 1:length(ns)){
  n <- ns[j]
  
  sim.res <- foreach(k=1:10000, .combine=rbind, .packages=c('lmerTest'),
                     .options.snow=opts) %dopar% {
                       
                       set.seed(m*(j-1) + k + 890000)
                       
                       ## generate and censor data (larger variability in random intercepts)
                       temp.dat <- gen_data(n, sd_b0 = 10, trt_eff = -10)
                       temp.dat <- censor_prev(temp.dat, alpha = 15.1, beta = -0.25)
                       
                       temp.dat <- na.omit(temp.dat)
                       
                       fit <- tryCatch(
                         {
                           ## try fitting model with random intercept + slope
                           lmerTest::lmer(y ~ y0 + t + A + (1 + t | ID), data = temp.dat, REML = TRUE)
                         },
                         error = function(e) {
                           ## if that fails, revert to random intercept only
                           lmerTest::lmer(y ~ y0 + t + A + (1 | ID), data = temp.dat, REML = TRUE)
                         }
                       )
                       
                       ## get effect estimate (for validation purposes) and p-value
                       sum.temp <- coef(summary(fit))[4,]
                       p.temp <- pt((sum.temp[1] + 10)/sum.temp[2], sum.temp[3], lower.tail = FALSE)
                       
                       as.numeric(c(sum.temp[1], p.temp))
                       
                     }
  
  ## save results as a .csv file
  write.csv(sim.res, paste0("conf_H0_lmm_var_n_", n, ".csv"), row.names = FALSE)
}

## get the confirmatory estimates for power and the type I error rate

## get the file names for power
files <- c("conf_lmm_prev_n_152.csv", "conf_lmm_slope_n_152.csv",
           "conf_lmm_time_n_152.csv", "conf_lmm_trt_n_152.csv",
           "conf_lmm_base_n_152.csv", "conf_lmm_var_n_152.csv")

## get a vector of power estimates for each scenario
pwr_conf <- NULL
for (j in 1:length(files)){
  sim.res <- read.csv(files[j])$V2
  pwr_conf[j] <- mean(sim.res <= 0.025)
}

## get file names for H0
filesH0 <- c("conf_H0_lmm_prev_n_152.csv", "conf_H0_lmm_slope_n_152.csv",
             "conf_H0_lmm_time_n_152.csv", "conf_H0_lmm_trt_n_152.csv",
             "conf_H0_lmm_base_n_152.csv", "conf_H0_lmm_var_n_152.csv")

## get a vector of type I error estimates for each scenario
t1E_conf <- NULL
for (j in 1:length(files)){
  sim.res <- read.csv(filesH0[j])$V2
  t1E_conf[j] <- mean(sim.res <= 0.025)
}